# ğŸ“„ DocuMind AI - Your Intelligent Document Assistant  

## ğŸ“ Introduction  
**DocuMind AI** is a **RAG (Retrieval-Augmented Generation) AI application** that allows users to upload PDFs and ask questions about their contents. It utilizes **LangChain** for document processing and retrieval, **Ollama** for running local LLMs, and **Mistral** for generating responses.  

---

## ğŸš€ Models Used  

| **Model** | **Usage** |
|-----------|----------|
| `mxbai-embed-large` | Converts document text into vector embeddings |
| `mistral` | Generates responses based on retrieved document context |

---

## ğŸ”„ Flow of the Application  

1. **User uploads a PDF document** ğŸ¡ª Stored in a local directory.  
2. **Text is extracted and split into chunks** ğŸ¡ª Using `RecursiveCharacterTextSplitter`.  
3. **Chunks are converted to vector embeddings** ğŸ¡ª Using `OllamaEmbeddings` (`mxbai-embed-large`).  
4. **Embeddings are stored in an in-memory vector store** (`InMemoryVectorStore`).  
5. **User asks a question** ğŸ¡ª The app retrieves **similar document chunks** using cosine similarity.  
6. **The most relevant context is passed to Mistral LLM** ğŸ¡ª Generates a well-structured answer.  
7. **The response is displayed in the chat UI**.  

---

## ğŸ“œ Summary Flow  

--# ğŸ“„ DocuMind AI  

DocuMind AI is a **Retrieval-Augmented Generation (RAG)** application that allows users to upload PDFs and ask questions about their contents. It leverages **Mistral LLM** for text generation and **mxbai-embed-large** for vector embeddings.  







---


## ğŸ› ï¸ Installation & Running Locally  

Follow these steps to run **DocuMind AI** on your local machine:  

### **1ï¸âƒ£ Install Ollama**  
Ollama is required to run local LLMs. Download and install it from the official site:  

ğŸ”— [Ollama Official Website](https://ollama.com)  

### **2ï¸âƒ£ Pull Required Models**  
DocuMind AI uses **Mistral** for text generation and **mxbai-embed-large** for embeddings. Pull them using:  

```sh
ollama pull mistral
ollama pull mxbai-embed-large
```

### **3ï¸âƒ£ Clone the Repository**

```sh
git clone https://github.com/notebook16/Document-RAG-GEN-AI.git
cd Document-RAG-GEN-AI
```

### **4ï¸âƒ£ Create a Virtual Environment**

```sh
python -m venv venv
source venv/bin/activate  # On macOS/Linux
venv\Scripts\activate     # On Windows
```

### **5ï¸âƒ£ Install Dependencies**

```sh
pip install -r requirements.txt
```

### **6ï¸âƒ£ Run the Application**

```sh
streamlit run app.py
```

---

## ğŸ¯ Features  

âœ… Upload and analyze PDFs ğŸ“„  
âœ… Retrieve the most relevant information ğŸ”  
âœ… Generate answers using Mistral LLM ğŸ¤–  
âœ… Fast and efficient vector search with in-memory storage ğŸš€  

---

## ğŸ“œ License  

This project is open-source and available under the **MIT License**.  

---


